{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9d04ee4-cce5-44c6-9a64-b05121090168",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09b1fb-b2be-4a48-8866-c13973480841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.ds import DeseqStats\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import label_binarize, LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold\n",
    ")\n",
    "\n",
    "from sklearn.metrics import ( \n",
    "    f1_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    confusion_matrix, \n",
    "    precision_recall_curve, \n",
    "    average_precision_score, \n",
    "    classification_report, \n",
    "    log_loss,\n",
    "    auc\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "import umap.umap_ as umap\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e657cb-8edb-4a6e-b9c0-d6b719dbba62",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9602d7-3c59-485f-9e6e-ae771f23899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "FOLDER_PATH = r'path'\n",
    "\n",
    "FPKM_PATH = F'{FOLDER_PATH}\\TCGA-BRCA.htseq_counts.tsv'\n",
    "UQ_PATH = F'{FOLDER_PATH}\\TCGA-BRCA.htseq_fpkm-uq.tsv'\n",
    "\n",
    "PROBE_MAP_PATH = F'{FOLDER_PATH}\\gencode.v22.annotation.gene.probeMap'\n",
    "PHENOTYPE_PATH = F'{FOLDER_PATH}\\TCGA-BRCA.GDC_phenotype.tsv'\n",
    "METADATA_PATH = F'{FOLDER_PATH}\\Lehmann_metadata.csv'\n",
    "\n",
    "# Load data\n",
    "expression_data = pd.read_csv(FPKM_PATH, sep='\\t')\n",
    "expression_data_UQ = pd.read_csv(UQ_PATH, sep='\\t')\n",
    "\n",
    "gene_annotation = pd.read_csv(PROBE_MAP_PATH, sep='\\t')\n",
    "phenotype_data = pd.read_csv(PHENOTYPE_PATH, sep='\\t')\n",
    "phenotype_data = phenotype_data.set_index(phenotype_data.columns[0])\n",
    "lehmann_metadata = pd.read_csv(METADATA_PATH, sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66b05e-a587-4879-8280-ebfa3262b68b",
   "metadata": {},
   "source": [
    "## data preprocessing - htseq_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe7c042-9de1-43bd-b2cf-892a4d0674e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging data\n",
    "merged_data = expression_data.merge(gene_annotation, left_on='Ensembl_ID', right_on='id', how='left')\n",
    "merged_data['Ensembl_ID'] = merged_data['gene'].fillna(merged_data['Ensembl_ID'])\n",
    "merged_data.drop(columns=['id', 'gene'], inplace=True)\n",
    "merged_data.set_index('Ensembl_ID', inplace=True)\n",
    "merged_data = merged_data[~merged_data.index.str.startswith('_')]\n",
    "\n",
    "# Handle genes with all zero\n",
    "filtered_merged_data = merged_data[merged_data.iloc[:, :1217].sum(axis=1) != 0]\n",
    "\n",
    "# Handle duplicate gene names\n",
    "duplicated_indices = filtered_merged_data.index[filtered_merged_data.index.duplicated(keep=False)]\n",
    "\n",
    "new_index = []\n",
    "\n",
    "for idx, row in filtered_merged_data.iterrows():\n",
    "    if idx in duplicated_indices:\n",
    "        new_idx = f\"{idx}_({row['chrom']}_{row['chromStart']}_{row['chromEnd']}_{row['strand']})\"\n",
    "        new_index.append(new_idx)\n",
    "    else:\n",
    "        new_index.append(idx)\n",
    "\n",
    "filtered_merged_data.index = new_index\n",
    "\n",
    "# Convert log2 values to raw counts\n",
    "raw_expression = filtered_merged_data.iloc[:, :1217].applymap(lambda x: 2**x - 1).T\n",
    "\n",
    "# Add phenotype info\n",
    "expression_with_samples = raw_expression.merge(phenotype_data[['sample_type.samples']], left_index=True, right_index=True, how='left')\n",
    "expression_with_samples.index = expression_with_samples.index.str.rstrip('A')\n",
    "\n",
    "# Add PAM50 data and handle 'Solid Tissue Normal' cases\n",
    "expression_with_pam50 = expression_with_samples.merge(lehmann_metadata[['PAM50']], left_index=True, right_index=True, how='left')\n",
    "expression_with_pam50.loc[expression_with_pam50['sample_type.samples'] == 'Solid Tissue Normal', 'PAM50'] = 'Solid Tissue Normal'\n",
    "\n",
    "# Data Cleaning\n",
    "filtered_data = expression_with_pam50.dropna(subset=['PAM50']).copy()\n",
    "zero_expression_genes = filtered_data.sum()[filtered_data.sum() == 0].index\n",
    "filtered_data.drop(zero_expression_genes, axis=1, inplace=True)\n",
    "\n",
    "# Extract and transform expression data\n",
    "expression_values = filtered_data.iloc[:, :-2]\n",
    "expression_values[\"PAM50\"] = filtered_data[\"PAM50\"]\n",
    "expression_values.index.name = 'Geneid'\n",
    "transformed_expression = expression_values.iloc[:, :-1].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dd864f-6eb1-4fe9-b65a-589b1e014d66",
   "metadata": {},
   "source": [
    "## DE analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea83fee-0920-430f-8d30-dd5c441a11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_extract_top_genes(df):\n",
    "    \"\"\"\n",
    "    Filter genes based on pvalue (padj) < 0.05 & abs(log2FoldChange) > 1.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): Input dataframe with genes data.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: \n",
    "        - DataFrame: Filtered genes based on pvalue and log2FoldChange.\n",
    "        - DataFrame: Number of differentially expressed genes.\n",
    "    \"\"\"\n",
    "    # First, drop rows with NaN values in the 'padj' column\n",
    "    df = df.dropna(subset=['padj'])\n",
    "    \n",
    "    # Filter only DE genes based on p-value (padj) and abs(log2FoldChange)\n",
    "    filtered_df = df[(df['padj'] < 0.05) & (abs(df['log2FoldChange']) > 1)]\n",
    "    \n",
    "    number_of_DE_genes = len(filtered_df.index)\n",
    "    de_genes_df = pd.DataFrame({\"Number_of_DE_genes\": [number_of_DE_genes]})\n",
    "    \n",
    "    return filtered_df, de_genes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52931e4d-eace-4306-9172-ae4229277035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gene_counts(top_genes_df, res_df, condition_name):\n",
    "    \"\"\"\n",
    "    Determine overexpressed and underexpressed genes, and calculate related statistics.\n",
    "\n",
    "    Parameters:\n",
    "    - top_genes_df (DataFrame): Input dataframe.\n",
    "    - res_df (DataFrame): Results dataframe from DESeq.\n",
    "    - condition_name (str): Name of the condition being processed.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Dataframe with statistics for specific condition.\n",
    "    \"\"\"\n",
    "    # Filter overexpressed genes.\n",
    "    overexpressed = top_genes_df[top_genes_df['log2FoldChange'] > 0]\n",
    "    \n",
    "    # Filter underexpressed genes.\n",
    "    underexpressed = top_genes_df[top_genes_df['log2FoldChange'] < 0]\n",
    "    \n",
    "    # Count overexpressed genes.\n",
    "    overexpressed_count = len(overexpressed)\n",
    "    \n",
    "    # Count underexpressed genes.\n",
    "    underexpressed_count = len(underexpressed)\n",
    "    \n",
    "    # Calculate the percentage of differentially expressed genes.\n",
    "    percentage = (de_genes_count_df.iloc[0, 0] / len(res_df)) * 100\n",
    "    \n",
    "    relative_overexpressed_percentage = overexpressed_count / de_genes_count_df.iloc[0, 0]\n",
    "    \n",
    "    relative_underexpressed_percentage = underexpressed_count / de_genes_count_df.iloc[0, 0]\n",
    "    \n",
    "    overexpressed_percentage = relative_overexpressed_percentage * percentage\n",
    "    underexpressed_percentage = relative_underexpressed_percentage * percentage\n",
    "\n",
    "    # Output do dict.\n",
    "    data = {\n",
    "        'Combination': condition_name,\n",
    "        'Number_of_DE_genes': de_genes_count_df.iloc[0, 0],\n",
    "        'Percentage_of_DE_genes': percentage,\n",
    "        'Overexpressed_Count': overexpressed_count,\n",
    "        'Underexpressed_Count': underexpressed_count,\n",
    "        'Overexpressed_Percentage': overexpressed_percentage,\n",
    "        'Underexpressed_Percentage': underexpressed_percentage\n",
    "    }\n",
    "\n",
    "    # Convert to df\n",
    "    return pd.DataFrame(data, index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b6699-112c-47b0-97f6-23ce0e9c96a1",
   "metadata": {},
   "source": [
    "#### Solid Tissue Normal vs PAM50 subtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb99ec2a-97c7-411d-8948-0fea48baf50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metadata\n",
    "metadata = pd.DataFrame({'Sample': expression_values.index.astype(str), 'Condition': expression_values[\"PAM50\"]}).set_index(\"Sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5744e7-ee78-4886-9d48-74f4de38ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run analysis\n",
    "dds = DeseqDataSet(counts = transformed_expression, metadata = metadata, design_factors = \"Condition\")\n",
    "dds.deseq2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c7ab4-140d-41ec-bb54-79946c2a5cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\"LumA\", \"LumB\", \"Her2\", \"Basal\", \"Normal\", \"Solid Tissue Normal\"]\n",
    "results_list = []\n",
    "res_dfs_list = []\n",
    "de_genes_counts_df_list = []\n",
    "\n",
    "for cond in conditions:\n",
    "    if cond != \"Solid Tissue Normal\":\n",
    "        stat_res = DeseqStats(dds, contrast=(\"Condition\", \"Solid Tissue Normal\", cond))\n",
    "        stat_res.summary()\n",
    "        res_df = stat_res.results_df\n",
    "        \n",
    "        res_dfs_list.append(res_df)\n",
    "        top_genes_df, de_genes_count_df = filter_and_extract_top_genes(res_df)\n",
    "        results_list.append(top_genes_df)\n",
    "        \n",
    "        condition_name = f\"Solid Tissue Normal vs {cond}\"\n",
    "        df = process_gene_counts(top_genes_df, res_df, condition_name)\n",
    "        de_genes_counts_df_list.append(df)\n",
    "\n",
    "de_genes_counts_df = pd.concat(de_genes_counts_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530dce4a-f356-45b3-9c8b-74b5633f0cd4",
   "metadata": {},
   "source": [
    "#### PAM50 subtypes combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d090f3-252b-49d1-9cbd-7baee17fd935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting data without Solid Tissue Normal samples\n",
    "expression_values2 = expression_values[expression_values['PAM50'] != 'Solid Tissue Normal']\n",
    "transformed_expression2 = expression_values2.iloc[:, :-1].T.dropna(inplace=False).T.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8ddb40-e4c1-4675-a81a-777d35779d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metadata\n",
    "metadata2 = pd.DataFrame({'Sample': expression_values2.index.astype(str), 'Condition': expression_values2[\"PAM50\"]}).set_index(\"Sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b6e7de-79ec-4172-a38e-3ed178fcae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\"LumA\", \"LumB\", \"Her2\", \"Basal\", \"Normal\"]\n",
    "combined_results_list = []\n",
    "combined_res_dfs_list = []\n",
    "combined_de_genes_counts_df_list = []\n",
    "\n",
    "for cond in conditions:\n",
    "    temp_metadata = metadata2.copy()\n",
    "    temp_metadata['Condition'] = temp_metadata['Condition'].apply(lambda x: cond if x == cond else 'Not ' + cond)\n",
    "    \n",
    "    dds = DeseqDataSet(counts=transformed_expression2, metadata=temp_metadata, design_factors=\"Condition\")\n",
    "    dds.deseq2()\n",
    "    \n",
    "    stat_res = DeseqStats(dds, contrast=(\"Condition\", cond, 'Not ' + cond))\n",
    "    stat_res.summary()\n",
    "    res_df = stat_res.results_df\n",
    "    \n",
    "    combined_res_dfs_list.append(res_df)\n",
    "    top_genes_df, de_genes_count_df = filter_and_extract_top_genes(res_df)\n",
    "    combined_results_list.append(top_genes_df)\n",
    "    \n",
    "    condition_name = f\"{cond} vs Not {cond}\"\n",
    "    df = process_gene_counts(top_genes_df, res_df, condition_name)\n",
    "    combined_de_genes_counts_df_list.append(df)\n",
    "\n",
    "combined_de_genes_counts_df = pd.concat(combined_de_genes_counts_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b18cb09-8138-487c-b5ad-94c8c29530c7",
   "metadata": {},
   "source": [
    "## preprocessing HTSeq - FPKM-UQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3640102b-5d2b-4b51-ac77-78333669a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging data\n",
    "merged_data_UQ = expression_data_UQ.merge(gene_annotation, left_on='Ensembl_ID', right_on='id', how='left')\n",
    "merged_data_UQ['Ensembl_ID'] = merged_data_UQ['gene'].fillna(merged_data_UQ['Ensembl_ID'])\n",
    "merged_data_UQ.drop(columns=['id', 'gene'], inplace=True)\n",
    "merged_data_UQ.set_index('Ensembl_ID', inplace=True)\n",
    "merged_data_UQ = merged_data_UQ[~merged_data_UQ.index.str.startswith('_')]\n",
    "\n",
    "# Handle genes with all zero\n",
    "filtered_merged_data_UQ = merged_data_UQ[merged_data.iloc[:, :1217].sum(axis=1) != 0]\n",
    "\n",
    "# Handle duplicate gene names\n",
    "duplicated_indices_UQ = filtered_merged_data_UQ.index[filtered_merged_data_UQ.index.duplicated(keep=False)]\n",
    "\n",
    "new_index = []\n",
    "\n",
    "for idx, row in filtered_merged_data_UQ.iterrows():\n",
    "    if idx in duplicated_indices_UQ:\n",
    "        new_idx = f\"{idx}_({row['chrom']}_{row['chromStart']}_{row['chromEnd']}_{row['strand']})\"\n",
    "        new_index.append(new_idx)\n",
    "    else:\n",
    "        new_index.append(idx)\n",
    "\n",
    "filtered_merged_data_UQ.index = new_index\n",
    "\n",
    "filtered_merged_data_UQ2 = filtered_merged_data_UQ.iloc[:, :1217].T\n",
    "\n",
    "filtered_merged_data_UQ2.index = filtered_merged_data_UQ2.index.str.rstrip('A') # this to find 20% variable set \n",
    "\n",
    "filtered_merged_data_UQ3 = filtered_merged_data_UQ2.merge(lehmann_metadata[['PAM50']], left_index=True, right_index=True, how='left')\n",
    "\n",
    "# Data Cleaning\n",
    "filtered_data_UQ = filtered_merged_data_UQ3.dropna(subset=['PAM50']).copy()\n",
    "zero_expression_genes_UQ = filtered_data_UQ.sum()[filtered_data_UQ.sum() == 0].index\n",
    "filtered_data_UQ.drop(zero_expression_genes_UQ, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b854fb-5bc7-4936-8f02-d7f0f0d9af0a",
   "metadata": {},
   "source": [
    "## Selecting 20% most variable genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8641fc37-4aab-4edf-a957-2cf40f00b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gene_variance_processed(df, percentage=20):\n",
    "    \"\"\"\n",
    "    Compute variance for each gene from pre-processed data and extract the top percentage of most variable genes.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): Sample-wise gene counts that are already processed and log transformed.\n",
    "    - percentage (float): Percentage of top variable genes to be extracted.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with the top percentage of most variable genes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute the variance for each gene using the original dataframe\n",
    "    variance = df.var(axis=0)\n",
    "    \n",
    "    # Sort variances in descending order\n",
    "    sorted_variance = variance.sort_values(ascending=False)\n",
    "    \n",
    "    # Extract top percentage of most variable genes\n",
    "    top_genes_count = int(len(sorted_variance) * (percentage / 100))\n",
    "    top_genes = sorted_variance.head(top_genes_count).index\n",
    "    \n",
    "    return df[top_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e9999-d30f-46b6-91d8-2e3639bfa8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute variance\n",
    "top_20_percent_genes_df = compute_gene_variance_processed(filtered_merged_data_UQ2, 20)\n",
    "\n",
    "# add PAM50 classification\n",
    "top_20_percent_genes_LM = top_20_percent_genes_df.merge(lehmann_metadata[['PAM50']], left_index=True, right_index=True, how='left')\n",
    "\n",
    "# Data Cleaning\n",
    "top_20_percent_genes_F = top_20_percent_genes_LM.dropna(subset=['PAM50']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398cc698-59b8-4dbe-b729-742884d42ea9",
   "metadata": {},
   "source": [
    "## Selecting only DE genes and extract these genes from HTSeq - FPKM-UQ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9ef007-7b41-44a6-81a4-5fdbbc7df131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both lists of DE genes into a single list\n",
    "all_results = results_list + combined_results_list\n",
    "\n",
    "# Extract genes from each dataframe and combine\n",
    "all_genes = []\n",
    "for df in all_results:\n",
    "    all_genes.extend(df.index.tolist())\n",
    "\n",
    "# Get unique genes\n",
    "unique_genes = set(all_genes)\n",
    "\n",
    "# Convert the set of unique genes to a DataFrame\n",
    "unique_genes_df = pd.DataFrame(list(unique_genes), columns=['gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d97f004-0126-4e01-8df3-79ca3bc91bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change row to columns\n",
    "mean_expression_UQ_T = filtered_merged_data_UQ2.T\n",
    "\n",
    "# selection based on colum 'gene'\n",
    "only_DE_genes = mean_expression_UQ_T[mean_expression_UQ_T.index.isin(unique_genes_df['gene'])].T\n",
    "\n",
    "# add PAM50 classification\n",
    "only_DE_genes_LM = only_DE_genes.merge(lehmann_metadata[['PAM50']], left_index=True, right_index=True, how='left')\n",
    "\n",
    "# Data Cleaning\n",
    "only_DE_genes_F = only_DE_genes_LM.dropna(subset=['PAM50']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc9e5d-b9ef-4304-9aba-eb14693ee7c7",
   "metadata": {},
   "source": [
    "## Dimension reduction & visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1a4620-80dc-42fb-b41f-286d34c749d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dimensionality_reduction(ax, X_transformed, y, title, explained_var=None):\n",
    "    \"\"\"\n",
    "    Plots 2D dimensionality reduction.\n",
    "    \n",
    "    Parameters:\n",
    "    - ax: The axis on which to plot.\n",
    "    - X_transformed: 2D array-like data after dimensionality reduction.\n",
    "    - y: Labels for the data points.\n",
    "    - title: Title of the plot.\n",
    "    - explained_var: Explained variance for PCA, default is None for other techniques.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a color mapping based on classes\n",
    "    classes = y.unique()\n",
    "    colors = plt.cm.jet(np.linspace(0, 1, len(classes)))  # Using the 'jet' colormap\n",
    "    color_map = dict(zip(classes, colors))\n",
    "\n",
    "    # Map classes to colors\n",
    "    y_colors = y.map(color_map)\n",
    "\n",
    "    # Plot \n",
    "    ax.scatter(X_transformed[:, 0], X_transformed[:, 1], c=y_colors)\n",
    "    ax.set_title(title)\n",
    "    if explained_var is not None:\n",
    "        ax.set_xlabel(f'PC1 ({explained_var[0]*100:.2f}%)')\n",
    "        ax.set_ylabel(f'PC2 ({explained_var[1]*100:.2f}%)')\n",
    "    else:\n",
    "        ax.set_xlabel('Component 1')\n",
    "        ax.set_ylabel('Component 2')\n",
    "\n",
    "    # Create proxy artists for the legend\n",
    "    proxies = [plt.Line2D([0], [0], linestyle='none', marker='o', markersize=10, markerfacecolor=color_map[class_]) for class_ in classes]\n",
    "\n",
    "    legend_data = list(zip(proxies, classes))\n",
    "    ax.legend(*zip(*legend_data), loc='center left', bbox_to_anchor=(1, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0d07a-728e-4cc9-b0f4-d0db5780cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PCA(X, y, n_components=2, figsize=(8, 5)):\n",
    "    \"\"\"\n",
    "    Apply PCA on data X and plot the results.\n",
    "\n",
    "    Parameters:\n",
    "    - X: array-like or pd.DataFrame, shape (n_samples, n_features)\n",
    "    - y: array-like, shape (n_samples,)\n",
    "    - n_components: int, default=2\n",
    "        Number of components for PCA.\n",
    "    - figsize: tuple, default=(8, 5)\n",
    "    \n",
    "    Returns:\n",
    "    - None. Displays a plot.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create PCA instance and transform data\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    # Create a new figure and axis\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # function to plot on this axis\n",
    "    plot_dimensionality_reduction(ax, X_pca, y, 'PCA', explained_var=pca.explained_variance_ratio_)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae13b79-294b-45c4-89d8-f722144a643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PCA_variance(X, n_components=50, figsize=(8, 5)):\n",
    "    \"\"\"\n",
    "    Apply PCA on data X and plot the explained variance and cumulative explained variance for each component (represented by Y axis).\n",
    "\n",
    "    Parameters:\n",
    "    - X: array-like or pd.DataFrame, shape (n_samples, n_features)\n",
    "    - n_components: int, default=50\n",
    "        Number of components for PCA.\n",
    "    - figsize: tuple, default=(8, 5)\n",
    "        Size of the figure.\n",
    "    \n",
    "    Returns:\n",
    "    - None. Displays a plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fit PCA \n",
    "    pca_full = PCA(n_components=n_components)\n",
    "    pca_full.fit_transform(X)\n",
    "\n",
    "    # Get the explained variance for each component\n",
    "    explained_variance = pca_full.explained_variance_ratio_\n",
    "\n",
    "    # Calculate the cumulative explained variance\n",
    "    cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "    # Plot explained variance for each component\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.7, align='center', label=\"Explained Variance\")\n",
    "    plt.plot(range(1, len(explained_variance) + 1), cumulative_variance, '-o', label=\"Cumulative Explained Variance\")\n",
    "    plt.xlabel('Number of components')\n",
    "    plt.ylabel('Variance (%)')\n",
    "    plt.title('PCA Explained Variance')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d35ce-36f5-41ac-bc45-c1cce0032cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_TSNE(X, y, init='random', figsize=(20, 20)):\n",
    "    \"\"\"\n",
    "    Apply t-SNE on data X with various perplexity and learning rate and plot the results.\n",
    "\n",
    "    Parameters:\n",
    "    - X: array-like or pd.DataFrame, shape (n_samples, n_features)\n",
    "    - y: array-like, shape (n_samples,)\n",
    "    - init: str, default='random'. Can be 'pca' \n",
    "    - figsize: tuple, default=(20, 20)\n",
    "\n",
    "    Returns:\n",
    "    - None. Displays a plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    # List of perplexity values\n",
    "    perplexity_values = [5, 30, 50, 100]\n",
    "    \n",
    "    # List of learning rates\n",
    "    learning_rates = [10, 100, 500, 1000]\n",
    "\n",
    "    # Setting up the figure for subplots\n",
    "    fig, axes = plt.subplots(len(perplexity_values), len(learning_rates), figsize=figsize)\n",
    "\n",
    "    # Iterating over different perplexity and learning rate and plot the results\n",
    "    for perplexity_row, perplexity in enumerate(perplexity_values):\n",
    "        for lr_col, lr in enumerate(learning_rates):\n",
    "            X_tsne = TSNE(n_components=2, init=init, perplexity=perplexity, learning_rate=lr).fit_transform(X)\n",
    "            plot_dimensionality_reduction(axes[perplexity_row, lr_col], X_tsne, y, f\"t-SNE\\nPerplexity: {perplexity}\\nLR: {lr}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86fc51b-d959-4ba0-b228-391ddd38ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_UMAP(X, y, figsize=(20, 20)):\n",
    "    \"\"\"\n",
    "    Apply UMAP on data X with various n_neighbors and min_dist and plot the results.\n",
    "\n",
    "    Parameters:\n",
    "    - X: array-like or pd.DataFrame, shape (n_samples, n_features)\n",
    "    - y: array-like, shape (n_samples,)\n",
    "    - figsize: tuple, default=(20, 20)\n",
    "    \n",
    "    Returns:\n",
    "    - None. Displays a plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    # List of n_neighbors values\n",
    "    n_neighbors_values = [5, 10, 50, 100]\n",
    "    \n",
    "    # List of min_dist values\n",
    "    min_dist_values = [0.01, 0.1, 0.5, 1.0]\n",
    "\n",
    "    # Setting up the figure for subplots\n",
    "    fig, axes = plt.subplots(len(n_neighbors_values), len(min_dist_values), figsize=figsize)\n",
    "\n",
    "    # Iterating over different n_neighbors and min_dist values and plot the results\n",
    "    for n_neighbors_row, n_neighbors in enumerate(n_neighbors_values):\n",
    "        for min_dist_col, min_dist in enumerate(min_dist_values):\n",
    "            reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist)\n",
    "            X_umap = reducer.fit_transform(X)\n",
    "            plot_dimensionality_reduction(axes[n_neighbors_row, min_dist_col], X_umap, y, f\"UMAP\\nNeighbors: {n_neighbors}\\nMin Dist: {min_dist}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2808d84f-b7dc-47d5-a43d-be61fbd4347b",
   "metadata": {},
   "source": [
    "dimension reduction & visualization for ALL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c721cb18-e138-4e81-aa09-9b3ae4cfe9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and the classes\n",
    "X = filtered_data_UQ.drop('PAM50', axis=1)\n",
    "y = filtered_data_UQ['PAM50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c632c9-3d0f-4e99-82a6-177e24cb1360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "plot_PCA(X, y)\n",
    "\n",
    "# PCA explained variance\n",
    "plot_PCA_variance(X)\n",
    "\n",
    "# T-SNE\n",
    "plot_TSNE(X, y, init='random')\n",
    "\n",
    "# T-SNE + PCA\n",
    "plot_TSNE(X, y, init='pca')\n",
    "\n",
    "# UMAP\n",
    "plot_UMAP(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e2f4e2-27c7-484e-8d96-c9bf63ce64ce",
   "metadata": {},
   "source": [
    "dimension reduction & visualization for 20% subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc6d0c-9cc6-48a3-8eba-0601185917f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and the classes\n",
    "X = top_20_percent_genes_F.drop('PAM50', axis=1)\n",
    "y = top_20_percent_genes_F['PAM50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030eb625-79dc-46c0-8a0b-a61ec7f5308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "plot_PCA(X, y)\n",
    "\n",
    "# PCA explained variance\n",
    "plot_PCA_variance(X)\n",
    "\n",
    "# T-SNE\n",
    "plot_TSNE(X, y, init='random')\n",
    "\n",
    "# T-SNE + PCA\n",
    "plot_TSNE(X, y, init='pca')\n",
    "\n",
    "# UMAP\n",
    "plot_UMAP(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aec27ef-1ec4-4192-a17b-82855c7ef721",
   "metadata": {},
   "source": [
    "Dimension reduction & visualization for DE genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba80556-b0b5-490b-ab88-05fa0c903cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and the classes\n",
    "X = only_DE_genes_F.drop('PAM50', axis=1)\n",
    "y = only_DE_genes_F['PAM50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff414b-5f32-440b-a611-6c811bd76d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "plot_PCA(X, y)\n",
    "\n",
    "# PCA explained variance\n",
    "plot_PCA_variance(X)\n",
    "\n",
    "# T-SNE\n",
    "plot_TSNE(X, y, init='random')\n",
    "\n",
    "# T-SNE + PCA\n",
    "plot_TSNE(X, y, init='pca')\n",
    "\n",
    "# UMAP\n",
    "plot_UMAP(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380e3b05-04c3-4db5-b1ed-1303b5b2a2d3",
   "metadata": {},
   "source": [
    "## Classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae5a7cf-7741-419f-83d1-9556c3feccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_splitting(df, target_column):\n",
    "    \"\"\"\n",
    "    Split dataframe into training (60%), validation (20%) and testing (blind) (20%) sets.\n",
    "\n",
    "    This function first separates the features (X) and target (y) from the dataframe.\n",
    "    It then encodes the target labels and splits the data into a 60-20-20 for\n",
    "    training, validation and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): Dataframe to split.\n",
    "    - target_column (str): The name of the column to be used as the target.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Contains training, validation, and testing datasets for features and targets\n",
    "             (X_train, X_val, X_test and y_train_encoded, y_val_encoded, y_test_encoded)\n",
    "             as well as the original target values (y).\n",
    "    \"\"\"\n",
    "\n",
    "    # Separate the dataframe into features (X) and target (y)\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Encode the target column using LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "\n",
    "    # Split the data into 60% training and 40% temporary set.\n",
    "    # Stratified sampling.\n",
    "    X_train, X_temp, y_train_encoded, y_temp_encoded = train_test_split(\n",
    "        X, y_encoded, test_size=0.4, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "\n",
    "    # Split the temporary data into 50% validation and 50% test,\n",
    "    # achieving a 20-20 split from the original dataset.\n",
    "    X_val, X_test, y_val_encoded, y_test_encoded = train_test_split(\n",
    "        X_temp, y_temp_encoded, test_size=0.5, random_state=42, stratify=y_temp_encoded\n",
    "    )\n",
    "\n",
    "    return X_train, X_val, X_test, y_train_encoded, y_val_encoded, y_test_encoded, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab57141-ad2d-4b2a-b349-c3492ba19016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X_train, y_train_encoded, classifiers, param_grid, X_val, y_val_encoded, classes):\n",
    "    \"\"\"\n",
    "    Train multiple classifiers using predefined parameters, training and validation set. \n",
    "\n",
    "    Parameters:\n",
    "    - X_train (DataFrame): Training data features.\n",
    "    - y_train_encoded (Series): Encoded training data labels.\n",
    "    - classifiers (dict): Dictionary of classifier names and their corresponding instances.\n",
    "    - param_grid (dict): Dictionary containing parameter grid for hyperparameter tuning.\n",
    "    - X_val (DataFrame): Validation data features.\n",
    "    - y_val_encoded (Series): Encoded validation data labels.\n",
    "    - classes (list): List of class labels.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Best model (hyperparameters) for each classifier.\n",
    "    - dict: Confusion matrices for each classifier.\n",
    "    - dict: Classification reports for each classifier.\n",
    "    - DataFrame: DataFrame with average metrics (precision, recall, f1-score) for each classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    best_models = {}\n",
    "    confusion_matrices = {}\n",
    "    class_reports = {}\n",
    "    avg_metrics = []\n",
    "\n",
    "    # Iterate over classifiers\n",
    "    for name, classifier in classifiers.items():\n",
    "\n",
    "        # Handle XGBoost\n",
    "        if name == \"XGBoost\":\n",
    "            # Create the XGBoost classifier\n",
    "            model = xgb.XGBClassifier(eval_metric=\"mlogloss\", # for multi-class classif.\n",
    "                                      num_class=len(classes),\n",
    "                                      n_estimators=1000)\n",
    "\n",
    "            # Use RandomizedSearchCV \n",
    "            random_search = RandomizedSearchCV(model,\n",
    "                                               param_distributions=param_grid[name],\n",
    "                                               n_iter=25,\n",
    "                                               scoring='f1_weighted',\n",
    "                                               n_jobs=-1,\n",
    "                                               cv=3,\n",
    "                                               verbose=0,\n",
    "                                               random_state=10)\n",
    "\n",
    "            # Define the early stopping\n",
    "            fit_params={\"early_stopping_rounds\":50,\n",
    "                        \"eval_set\":[(X_val, y_val_encoded)],\n",
    "                        \"verbose\": False}\n",
    "\n",
    "            # Fit the RandomizedSearchCV with early stopping\n",
    "            random_search.fit(X_train, y_train_encoded, **fit_params)\n",
    "\n",
    "            best_models[name] = random_search.best_estimator_\n",
    "\n",
    "        else:\n",
    "            # Use RandomizedSearchCV for other models\n",
    "            random_search = RandomizedSearchCV(classifier,\n",
    "                                               param_distributions=param_grid[name],\n",
    "                                               n_iter=25,\n",
    "                                               scoring='f1_weighted',\n",
    "                                               n_jobs=-1,\n",
    "                                               cv=3,\n",
    "                                               verbose=0,\n",
    "                                               random_state=10)\n",
    "            random_search.fit(X_train, y_train_encoded)\n",
    "            best_models[name] = random_search.best_estimator_\n",
    "\n",
    "        # Evaluate training on validation set\n",
    "        if name == \"XGBoost\":\n",
    "            y_pred_proba = best_models[name].predict_proba(X_val)\n",
    "            y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        else:\n",
    "            y_pred = best_models[name].predict(X_val)\n",
    "\n",
    "        # Confusion matrices\n",
    "        confusion_matrices[name] = confusion_matrix(y_val_encoded, y_pred)\n",
    "        class_reports[name] = classification_report(y_val_encoded, y_pred, target_names=classes, output_dict=True)\n",
    "        \n",
    "        # weighted average mmetrics\n",
    "        avg_metrics.append({\n",
    "            'model': name,\n",
    "            'precision': class_reports[name]['weighted avg']['precision'],\n",
    "            'recall': class_reports[name]['weighted avg']['recall'],\n",
    "            'f1-score': class_reports[name]['weighted avg']['f1-score']\n",
    "        })\n",
    "\n",
    "    # Convert confusion_matrices into DataFrames\n",
    "    for name, matrix in confusion_matrices.items():\n",
    "        confusion_matrices[name] = pd.DataFrame(matrix,\n",
    "                                                index=classes,\n",
    "                                                columns=classes)\n",
    "\n",
    "    # Convert class_reports into DataFrames\n",
    "    for name, report in class_reports.items():\n",
    "        class_reports[name] = pd.DataFrame(report).transpose()\n",
    "        \n",
    "        # Keep only precission, recall, f1-score\n",
    "        class_reports[name] = class_reports[name][['precision', 'recall', 'f1-score']]\n",
    "        class_reports[name] = class_reports[name].drop(['accuracy', 'macro avg', 'weighted avg'])\n",
    "\n",
    "    avg_metrics_df = pd.DataFrame(avg_metrics).sort_values(by='f1-score', ascending=False)\n",
    "\n",
    "    return best_models, confusion_matrices, class_reports, avg_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06691666-64b0-457f-b2e4-efde31b14bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall(X_val, y_val_encoded, best_models, y):\n",
    "    \"\"\"\n",
    "    Plot the Precision-Recall (PR) curve with AUC for each classifier for the best_models.\n",
    "\n",
    "    Parameters:\n",
    "    - X_val (DataFrame): Validation data features.\n",
    "    - y_val_encoded (Series): Encoded validation data labels.\n",
    "    - best_models (dict): Dictionary of classifier names and their best-trained models.\n",
    "    - y (Series): Original series containing the labels for the entire dataset.\n",
    "\n",
    "    Returns:\n",
    "    - None. The function directly plots the Precision-Recall curves with AUC for each classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract unique class labels\n",
    "    classes = y.unique().tolist()\n",
    "\n",
    "    # Convert the encoded validation labels to binary format\n",
    "    y_bin = label_binarize(y_val_encoded, classes=range(len(classes)))\n",
    "\n",
    "    # Iterate over the classifiers in the dictionary of best models\n",
    "    for name, best_clf in best_models.items():\n",
    "        \n",
    "        #  Probability scores based on classifier \n",
    "        if name == \"XGBoost\":\n",
    "            val_scores = best_clf.predict_proba(X_val)  \n",
    "        elif hasattr(best_clf, \"decision_function\"):\n",
    "            val_scores = best_clf.decision_function(X_val)\n",
    "        else:\n",
    "            val_scores = best_clf.predict_proba(X_val)\n",
    "\n",
    "        precision = dict()\n",
    "        recall = dict()\n",
    "        average_precision = dict()\n",
    "        pr_auc = dict()\n",
    "\n",
    "        # For each class, compute Precision, Recall, and AUC values\n",
    "        for i, class_ in enumerate(classes):\n",
    "            precision[i], recall[i], _ = precision_recall_curve(y_bin[:, i], val_scores[:, i])\n",
    "            average_precision[i] = average_precision_score(y_bin[:, i], val_scores[:, i])\n",
    "            pr_auc[i] = auc(recall[i], precision[i])\n",
    "\n",
    "        # Plot PR curves for each class with AUC\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        for i, class_ in enumerate(classes):\n",
    "            plt.plot(recall[i], precision[i], lw=2, \n",
    "                     label=f\"PR curve of class {class_} (AUC = {pr_auc[i]:.3f})\")\n",
    "        plt.xlabel(\"Recall\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        plt.title(f\"Precision-Recall Curve with AUC - {name}\")\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd32200-b284-4211-831d-57a5d2e4e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(X_test, y_test_encoded, best_models, classes):\n",
    "    \"\"\"Test the trained models on test (blind) data.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_test (DataFrame): Test data features.\n",
    "    - y_test_encoded (array): Encoded labels for test data.\n",
    "    - best_models (dict): Dictionary containing trained models.\n",
    "    - classes (list): Names of the classes.\n",
    "    \n",
    "    Returns:\n",
    "    - test_results_df (DataFrame): Testing results for each model.\n",
    "    - confusion_matrices (dict): Confusion matrices for each model.\n",
    "    - class_reports (dict): Detailed classification report for each model.\n",
    "    \"\"\"\n",
    "    \n",
    "    test_results = []         \n",
    "    confusion_matrices = {}  \n",
    "    class_reports = {}      \n",
    "\n",
    "    # Iterate through each model in the best_models\n",
    "    for name, best_clf in best_models.items():\n",
    "        \n",
    "        # If model is XGBoost, use predict_proba method for predictions\n",
    "        if name == \"XGBoost\":\n",
    "            y_pred_proba = best_clf.predict_proba(X_test)\n",
    "            test_preds = np.argmax(y_pred_proba, axis=1)\n",
    "        else:\n",
    "            test_preds = best_clf.predict(X_test)\n",
    "\n",
    "        # Calculate weighted precision, recall, and F1 score\n",
    "        test_precision = precision_score(y_test_encoded, test_preds, average='weighted', zero_division=1)\n",
    "        test_recall = recall_score(y_test_encoded, test_preds, average='weighted')\n",
    "        test_f1 = f1_score(y_test_encoded, test_preds, average='weighted')\n",
    "        \n",
    "        # Produce classification report\n",
    "        report = classification_report(y_test_encoded, test_preds, target_names=classes, zero_division=1, output_dict=True)\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        \n",
    "        # Include only precision, recall, F1-score\n",
    "        report_df = report_df[['precision', 'recall', 'f1-score']]\n",
    "        report_df = report_df.drop(['accuracy', 'macro avg', 'weighted avg'], errors='ignore')\n",
    "        \n",
    "        # Produce confusion matrix \n",
    "        cm = confusion_matrix(y_test_encoded, test_preds)\n",
    "        confusion_df = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "        \n",
    "        # Store metrics for this model in the test_results list\n",
    "        test_results.append({\n",
    "            'Model': name,\n",
    "            'Test Precision': test_precision,\n",
    "            'Test Recall': test_recall,\n",
    "            'Test F1 Score': test_f1\n",
    "        })\n",
    "\n",
    "        # Update confusion_matrices and class_reports dictionaries\n",
    "        confusion_matrices[name] = confusion_df\n",
    "        class_reports[name] = report_df\n",
    "\n",
    "    # Convert test results into a DataFrame\n",
    "    test_results_df = pd.DataFrame(test_results)\n",
    "    \n",
    "    return test_results_df, confusion_matrices, class_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55cf3ed-2ca7-4d38-b2de-f2ab88ea0010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_evaluation(X_val, y_val_encoded, best_models, X_train, y_train_encoded):\n",
    "    \"\"\"Directly evaluate feature importances for each model and each class.\n",
    "\n",
    "    Parameters:\n",
    "    - X_val (DataFrame): Validation data features.\n",
    "    - y_val_encoded (array): Encoded labels for validation data.\n",
    "    - best_models (dict): Dictionary containing trained models.\n",
    "    - X_train (DataFrame): Training data features.\n",
    "    - y_train_encoded (array): Encoded labels for training data.\n",
    "\n",
    "    Returns:\n",
    "    - feature_importances (dict): Feature importances (first 50 featuers) for each model and each class.\n",
    "    \"\"\"\n",
    "    \n",
    "     # Feature list in the training data\n",
    "    genes = X_train.columns \n",
    "    \n",
    "     # Feature importance dict\n",
    "    feature_importances = {}\n",
    "\n",
    "    #  Unique class labels\n",
    "    unique_classes = np.unique(y_val_encoded)\n",
    "\n",
    "    # Iterate through each model in the best_models\n",
    "    for name, best_clf in best_models.items():\n",
    "        if name == \"XGBoost\":\n",
    "            for class_index in unique_classes:\n",
    "                binary_y_train = (y_train_encoded == class_index).astype(int)\n",
    "                best_params = best_clf.get_params() \n",
    "                model = XGBClassifier(**best_params)\n",
    "                model.fit(X_train, binary_y_train)\n",
    "                importances = model.feature_importances_\n",
    "                sorted_idx = importances.argsort()[::-1]\n",
    "                top_50_idx = sorted_idx[:50]\n",
    "\n",
    "                importance_df = pd.DataFrame({\n",
    "                    \"feature\": genes[top_50_idx],\n",
    "                    \"importance\": importances[top_50_idx]\n",
    "                })\n",
    "                feature_importances[name + f\"_Class_{class_index}\"] = importance_df\n",
    "\n",
    "        elif name == \"RandomForest\":\n",
    "            for class_index in unique_classes:\n",
    "                binary_y_train = (y_train_encoded == class_index).astype(int)\n",
    "                best_params = best_clf.get_params()\n",
    "                model = RandomForestClassifier(**best_params)\n",
    "                model.fit(X_train, binary_y_train)\n",
    "                importances = model.feature_importances_\n",
    "                sorted_idx = importances.argsort()[::-1]\n",
    "                top_50_idx = sorted_idx[:50]\n",
    "\n",
    "                importance_df = pd.DataFrame({\n",
    "                    \"feature\": genes[top_50_idx],\n",
    "                    \"importance\": importances[top_50_idx]\n",
    "                })\n",
    "                feature_importances[name + f\"_Class_{class_index}\"] = importance_df\n",
    "\n",
    "        elif name == \"LogisticRegression\":\n",
    "            for class_index in unique_classes:\n",
    "                importances = np.abs(best_clf.coef_[class_index])\n",
    "                sorted_idx = importances.argsort()[::-1]\n",
    "                top_50_idx = sorted_idx[:50]\n",
    "\n",
    "                importance_df = pd.DataFrame({\n",
    "                    \"feature\": genes[top_50_idx],\n",
    "                    \"importance\": importances[top_50_idx]\n",
    "                })\n",
    "                feature_importances[name + f\"_Class_{class_index}\"] = importance_df\n",
    "                \n",
    "    return feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc10cbff-aa3b-4e15-b610-b92eaa1a7a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "classifiers = {\n",
    "    \"RandomForest\": RandomForestClassifier(class_weight='balanced'),\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective='multi:softprob'),\n",
    "    \"LogisticRegression\": LogisticRegression(class_weight='balanced', max_iter=1000, multi_class='ovr', solver='saga')\n",
    "}\n",
    "\n",
    "# Hyperparameters\n",
    "param_dist = {\n",
    "    \"RandomForest\": {\n",
    "        'n_estimators': [10, 50, 100, 200, 500],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 4, 5, 6],\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'], \n",
    "        'solver': ['saga']  \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7313e5-1c5e-4541-9c86-16bd34200403",
   "metadata": {},
   "source": [
    "Models - all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfe6480-1292-47b9-8e3d-31fedb414a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split\n",
    "X_train, X_val, X_test, y_train_encoded, y_val_encoded, y_test_encoded, y = data_splitting(filtered_data_UQ, 'PAM50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c8e877-5a35-4689-925d-0946be4d3a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models + metrics\n",
    "best_models, confusion_matrices, class_reports, avg_metrics_df = train_and_evaluate(X_train, y_train_encoded, classifiers, param_dist, X_val, y_val_encoded, y.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259a117e-7ac8-4a21-ab70-2df2ad526d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PR curve\n",
    "plot_precision_recall(X_val, y_val_encoded, best_models, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc40533-eb04-4599-ba12-fc1e606ba5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performances on blind data\n",
    "test_results_df, test_confusion_matrices, test_class_reports = test_models(X_test, y_test_encoded, best_models, y.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b0c0a-f004-4111-a1a7-e3e15b39e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances (50 genes printed)\n",
    "feature_importances = feature_importance_evaluation(X_val, y_val_encoded, best_models, X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb690539-09a7-4937-a88e-d47ddcad9d7a",
   "metadata": {},
   "source": [
    "Models - DE set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833d4ab-a4c7-42ea-b33d-fd359d8c80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split\n",
    "X_train, X_val, X_test, y_train_encoded, y_val_encoded, y_test_encoded, y = data_splitting(only_DE_genes_F, 'PAM50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901a161b-d24d-4cad-92ba-207d9d761041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models + metrics\n",
    "best_models, confusion_matrices, class_reports, avg_metrics_df = train_and_evaluate(X_train, y_train_encoded, classifiers, param_dist, X_val, y_val_encoded, y.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eac1b9e-bd8f-41c5-81b9-c38dfc31875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PR curve\n",
    "plot_precision_recall(X_val, y_val_encoded, best_models, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1c02a9-fc55-414b-b93c-abafa9685049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performances on blind data\n",
    "test_results_df, test_confusion_matrices, test_class_reports = test_models(X_test, y_test_encoded, best_models, y.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c41fff-3afe-4a32-8e0c-24b9a13f2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances (50 genes printed)\n",
    "feature_importances = feature_importance_evaluation(X_val, y_val_encoded, best_models, X_train, y_train_encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
